{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1906791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from utils import find_reverse, random_choose, parse_response, strip_end\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5f9a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_match_APIs = [\n",
    "    'Global Email V4%%Global Email V4',\n",
    "    'BART%%Advisory information',\n",
    "    'JAK_API%%Ben 10',\n",
    "    'colegiosantaana%%Disciplina-1',\n",
    "    'MikuAPI%%getRandomImage',\n",
    "    'Handball Data%%Daily Match List-Scheduled',\n",
    "    'Token API%%generate',\n",
    "    'Numbers Translator%%Numbers Translator',\n",
    "    'Password Generator API%%Password of length 50',\n",
    "    'Places%%Geographic coordinates by placename',\n",
    "    'pizzaallapala%%Get Producto Promo',\n",
    "    'Password Generator API%%Base',\n",
    "    'JAK_API%%Brawl Stars',\n",
    "    'siteDomain%%language list',\n",
    "    'Fluximmo%%get_portail_api',\n",
    "    'NumbersToLetters%%Convertir cantidad a letra Moneda MXN Ingles',\n",
    "    'thailand%%thai4',\n",
    "    'colegiosantaana%%Mensajes-1',\n",
    "    'Soccer Data%%Tournament List',\n",
    "    'Marvel Vs Capcom 2%%All Characters',\n",
    "    'JAK_API%%Miraculous',\n",
    "    'NumbersToLetters%%Convertir cantidad a letra Moneda MXN Espa√±ol',\n",
    "    'F1 Latest News%%GET recent F1 news from all sources',\n",
    "    'get_today_date',\n",
    "    'Numbers%%Get math fact',\n",
    "    'forecast_weather',\n",
    "    'Car database%%Makes',\n",
    "    'colegiosantaana%%Evaluaciones-1',\n",
    "    'JAK_API%%Genshin Impact',\n",
    "    'Football Dolphin%%Head to head statistics',\n",
    "    'add_date',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d775db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_llm import chat_my, visualize_messages, get_chat_completion_my\n",
    "model_ckpts = 'gpt-3.5-turbo-16k-0613'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9084be2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pred_file(file_name, key_output='model_output', is_parsed=False, visualize=False):\n",
    "\n",
    "    with open(file_name, \"r\", encoding='utf-8') as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "    for gt_api in dataset:\n",
    "\n",
    "        examples = dataset[gt_api]\n",
    "        for ii in range(len(examples)):\n",
    "            item = examples[ii]\n",
    "        \n",
    "            item['no_call'] = 0\n",
    "            if is_parsed:\n",
    "                parsed = item['parsed_result']\n",
    "            else:\n",
    "                res = item[key_output].strip()\n",
    "                parsed = parse_response(res, API_name_list=list(dataset.keys()), api_descriptions=\"XXX\", proc_toolken=True, ground_API=True)\n",
    "            \n",
    "            if parsed['finish']:\n",
    "                item['err'] = 0\n",
    "                item['no_call'] = 1\n",
    "                examples[ii] = item\n",
    "                continue\n",
    "            \n",
    "            if not parsed['parse_successful']:\n",
    "                item['err'] = 1\n",
    "                examples[ii] = item\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                json.loads(parsed['action_input'])\n",
    "            except:\n",
    "                item['err'] = 1\n",
    "                examples[ii] = item\n",
    "                continue\n",
    "                \n",
    "            item['err'] = 0\n",
    "            \n",
    "            if parsed['action'] != gt_api:\n",
    "                item['api_match'] = 0\n",
    "            else:\n",
    "                item['api_match'] = 1\n",
    "                \n",
    "                gt_action_input = item['action_input']\n",
    "                model_action_input = parsed['action_input']\n",
    "\n",
    "                gt_dict = json.loads(gt_action_input)                \n",
    "                model_dict = json.loads(model_action_input)\n",
    "\n",
    "                # check semantic correctenss based on API call\n",
    "                if gt_api in string_match_APIs:\n",
    "                    # check via string matching\n",
    "                    string_same = True\n",
    "\n",
    "                    for key, val in gt_dict.items():\n",
    "                        if key in model_dict and str(model_dict[key]).strip().lower() == str(val).strip().lower():\n",
    "                            pass\n",
    "                        else:\n",
    "                            string_same = False\n",
    "                            break\n",
    "                    item['args_correct'] = int(string_same)\n",
    "\n",
    "                else:\n",
    "                    # check the correctness via ChatGPT\n",
    "                    messages = [\n",
    "                        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "                    ]\n",
    "\n",
    "                    msg = \"Your task is to judge whether an API call is correct with respect to the given ground truth API call. Note that the API call doesn't have to be exactly the\" \\\n",
    "                    \" same as the ground truth; it only needs to be semantically correct. It should not miss any important details in the arguments.\\n\\n\" \\\n",
    "                    \"The ground truth API call is:\\nAPI name: {}\\nAPI arguments: {}\\n\\n\" \\\n",
    "                    \"The API call that you need to verify the correctness is:\\nAPI name: {}\\nAPI arguments: {}\\n\\n\" \\\n",
    "                    \"Now say your judgment. Your response should always start with \\\"Yes.\\\" or \\\"No.\\\" indicating whether it's correct.\\nYour response:\"\n",
    "\n",
    "                    jud = chat_my(messages, msg.format(gt_api, json.dumps(gt_dict), gt_api, json.dumps(model_dict)), \n",
    "                                  temp=0.0, stop=\"Observation:\", visualize=visualize, max_tokens=256, model=model_ckpts)[-1]['content']\n",
    "\n",
    "                    item['args_correct'] = int(\"No.\" not in jud)\n",
    "                    \n",
    "            examples[ii] = item\n",
    "\n",
    "        dataset[gt_api] = examples\n",
    "\n",
    "    with open(file_name, \"w\", encoding='utf-8') as f:\n",
    "        json.dump(dataset, f)\n",
    "        \n",
    "        \n",
    "def eval_batch(file_name, key_list=None):\n",
    "    if type(file_name) == str:\n",
    "        with open(file_name, \"r\") as f:\n",
    "            dataset_evaled = json.load(f)\n",
    "    else:\n",
    "        dataset_evaled = file_name\n",
    "    \n",
    "    correct = 0\n",
    "    syntax_err, no_call = 0, 0\n",
    "    total = 0\n",
    "    api_match = 0\n",
    "    non_err = 0\n",
    "        \n",
    "    for key, examples in dataset_evaled.items():\n",
    "        if not (key_list is None or key in key_list):\n",
    "            continue\n",
    "\n",
    "        for item in examples:\n",
    "            total += 1\n",
    "            \n",
    "            if item['no_call']:\n",
    "                no_call += 1\n",
    "                continue\n",
    "            \n",
    "            if item['err']:\n",
    "                syntax_err += 1\n",
    "                continue\n",
    "                \n",
    "            non_err += 1\n",
    "            \n",
    "            if item['api_match']:\n",
    "                api_match += 1\n",
    "                correct += item['args_correct']\n",
    "                continue\n",
    "    \n",
    "    print(\"% wellformed:\", round(100*(non_err/total), 3))\n",
    "    print(\"% api match:\", round(100*api_match/non_err, 3))\n",
    "    print(\"% correct:\", round(100*correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b9350b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86583712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% wellformed: 98.133\n",
      "% api match: 49.049\n",
      "% correct: 37.333\n"
     ]
    }
   ],
   "source": [
    "eval_batch(\"saved_results/toolLLMv2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d891456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% wellformed: 34.533\n",
      "% api match: 40.154\n",
      "% correct: 10.667\n",
      "----\n",
      "% wellformed: 58.267\n",
      "% api match: 86.728\n",
      "% correct: 41.733\n",
      "----\n",
      "% wellformed: 99.2\n",
      "% api match: 94.892\n",
      "% correct: 73.333\n"
     ]
    }
   ],
   "source": [
    "eval_batch(\"saved_results/llama-7Bf.json\")\n",
    "print(\"----\")\n",
    "eval_batch(\"saved_results/llama-7Bf_ICL.json\")\n",
    "print(\"----\")\n",
    "eval_batch(\"saved_results/llama-7Bf_FT.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbdc0df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% wellformed: 79.333\n",
      "% api match: 53.613\n",
      "% correct: 32.667\n",
      "----\n",
      "% wellformed: 87.467\n",
      "% api match: 86.585\n",
      "% correct: 62.933\n",
      "----\n",
      "% wellformed: 98.933\n",
      "% api match: 95.148\n",
      "% correct: 74.267\n"
     ]
    }
   ],
   "source": [
    "eval_batch(\"saved_results/llama-13Bf.json\")\n",
    "print(\"----\")\n",
    "eval_batch(\"saved_results/llama-13Bf_ICL.json\")\n",
    "print(\"----\")\n",
    "eval_batch(\"saved_results/llama-13Bf_FT.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5999ea0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% wellformed: 61.733\n",
      "% api match: 69.33\n",
      "% correct: 30.133\n",
      "----\n",
      "% wellformed: 69.867\n",
      "% api match: 88.359\n",
      "% correct: 47.867\n",
      "----\n",
      "% wellformed: 99.067\n",
      "% api match: 95.828\n",
      "% correct: 76.8\n"
     ]
    }
   ],
   "source": [
    "eval_batch(\"saved_results/mistral.json\")\n",
    "print(\"----\")\n",
    "eval_batch(\"saved_results/mistral_ICL.json\")\n",
    "print(\"----\")\n",
    "eval_batch(\"saved_results/mistral_FT.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8379f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% wellformed: 96.933\n",
      "% api match: 77.579\n",
      "% correct: 60.533\n",
      "---\n",
      "% wellformed: 97.6\n",
      "% api match: 90.847\n",
      "% correct: 75.6\n"
     ]
    }
   ],
   "source": [
    "eval_batch(\"saved_results/gpt35.json\")\n",
    "print(\"---\")\n",
    "eval_batch(\"saved_results/gpt35_ICL.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e4af3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% wellformed: 96.133\n",
      "% api match: 78.086\n",
      "% correct: 60.8\n",
      "---\n",
      "% wellformed: 97.733\n",
      "% api match: 92.769\n",
      "% correct: 76.267\n"
     ]
    }
   ],
   "source": [
    "eval_batch(\"saved_results/gpt4.json\")\n",
    "print(\"---\")\n",
    "eval_batch(\"saved_results/gpt4_ICL.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7ff9773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% wellformed: 89.867\n",
      "% api match: 79.377\n",
      "% correct: 50.533\n",
      "--\n",
      "% wellformed: 99.733\n",
      "% api match: 70.588\n",
      "% correct: 53.867\n",
      "--\n",
      "% wellformed: 98.667\n",
      "% api match: 79.865\n",
      "% correct: 59.733\n",
      "--\n",
      "% wellformed: 99.333\n",
      "% api match: 81.745\n",
      "% correct: 60.133\n"
     ]
    }
   ],
   "source": [
    "# ablations\n",
    "eval_batch(\"saved_results/llama-7Bf_FT_no_exec.json\")\n",
    "print(\"--\")\n",
    "eval_batch(\"saved_results/llama-7Bf_FT_no_STM.json\")\n",
    "print(\"--\")\n",
    "eval_batch(\"saved_results/llama-7Bf_FT_no_LTM.json\")\n",
    "print(\"--\")\n",
    "eval_batch(\"saved_results/llama-7Bf_FT_no_reflection.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faa95033",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tool_metadata/CL_batches.json\") as f:\n",
    "    batches = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "099f3994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "% wellformed: 100.0\n",
      "% api match: 92.222\n",
      "% correct: 73.333\n",
      "--\n",
      "batch 1\n",
      "% wellformed: 100.0\n",
      "% api match: 98.974\n",
      "% correct: 87.179\n",
      "--\n",
      "batch 2\n",
      "% wellformed: 100.0\n",
      "% api match: 92.778\n",
      "% correct: 68.333\n",
      "--\n",
      "batch 3\n",
      "% wellformed: 95.897\n",
      "% api match: 96.791\n",
      "% correct: 67.179\n",
      "--\n",
      "% wellformed: 98.933\n",
      "% api match: 95.283\n",
      "% correct: 74.133\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(\"batch\", i)\n",
    "    eval_batch(\"saved_results/llama-7Bf_FT_flan.json\", batches[i])\n",
    "    print(\"--\")\n",
    "eval_batch(\"saved_results/llama-7Bf_FT_flan.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "763b7124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round: 0\n",
      "=====\n",
      "batch 0\n",
      "% wellformed: 99.444\n",
      "% api match: 98.883\n",
      "% correct: 80.556\n",
      "--\n",
      "total:\n",
      "% wellformed: 99.444\n",
      "% api match: 98.883\n",
      "% correct: 80.556\n",
      "=============================\n",
      "round: 1\n",
      "=====\n",
      "batch 0\n",
      "% wellformed: 97.778\n",
      "% api match: 94.886\n",
      "% correct: 76.111\n",
      "--\n",
      "batch 1\n",
      "% wellformed: 100.0\n",
      "% api match: 96.923\n",
      "% correct: 84.103\n",
      "--\n",
      "total:\n",
      "% wellformed: 98.933\n",
      "% api match: 95.957\n",
      "% correct: 80.267\n",
      "=============================\n",
      "round: 2\n",
      "=====\n",
      "batch 0\n",
      "% wellformed: 100.0\n",
      "% api match: 87.222\n",
      "% correct: 70.556\n",
      "--\n",
      "batch 1\n",
      "% wellformed: 100.0\n",
      "% api match: 97.436\n",
      "% correct: 84.103\n",
      "--\n",
      "batch 2\n",
      "% wellformed: 100.0\n",
      "% api match: 91.667\n",
      "% correct: 65.556\n",
      "--\n",
      "total:\n",
      "% wellformed: 100.0\n",
      "% api match: 92.252\n",
      "% correct: 73.694\n",
      "=============================\n",
      "round: 3\n",
      "=====\n",
      "batch 0\n",
      "% wellformed: 100.0\n",
      "% api match: 82.778\n",
      "% correct: 65.0\n",
      "--\n",
      "batch 1\n",
      "% wellformed: 100.0\n",
      "% api match: 97.436\n",
      "% correct: 88.718\n",
      "--\n",
      "batch 2\n",
      "% wellformed: 100.0\n",
      "% api match: 87.222\n",
      "% correct: 66.111\n",
      "--\n",
      "batch 3\n",
      "% wellformed: 92.308\n",
      "% api match: 97.222\n",
      "% correct: 70.256\n",
      "--\n",
      "total:\n",
      "% wellformed: 98.0\n",
      "% api match: 91.293\n",
      "% correct: 72.8\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "for round_ in range(4):\n",
    "    print(\"round:\", round_)\n",
    "    print(\"=====\")\n",
    "    for i in range(round_+1):\n",
    "        print(\"batch\", i)\n",
    "        eval_batch(\"saved_results/CL_round_{}.json\".format(round_), batches[i])\n",
    "        print(\"--\")\n",
    "    print(\"total:\")\n",
    "    eval_batch(\"saved_results/CL_round_{}.json\".format(round_))\n",
    "    print(\"=============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ef56e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round: 1\n",
      "=====\n",
      "batch 0\n",
      "% wellformed: 98.889\n",
      "% api match: 2.247\n",
      "% correct: 1.667\n",
      "--\n",
      "batch 1\n",
      "% wellformed: 100.0\n",
      "% api match: 96.923\n",
      "% correct: 87.692\n",
      "--\n",
      "total:\n",
      "% wellformed: 99.467\n",
      "% api match: 51.743\n",
      "% correct: 46.4\n",
      "=============================\n",
      "round: 2\n",
      "=====\n",
      "batch 0\n",
      "% wellformed: 97.778\n",
      "% api match: 0.0\n",
      "% correct: 0.0\n",
      "--\n",
      "batch 1\n",
      "% wellformed: 99.487\n",
      "% api match: 63.918\n",
      "% correct: 56.923\n",
      "--\n",
      "batch 2\n",
      "% wellformed: 100.0\n",
      "% api match: 92.778\n",
      "% correct: 68.889\n",
      "--\n",
      "total:\n",
      "% wellformed: 99.099\n",
      "% api match: 52.909\n",
      "% correct: 42.342\n",
      "=============================\n",
      "round: 3\n",
      "=====\n",
      "batch 0\n",
      "% wellformed: 100.0\n",
      "% api match: 0.0\n",
      "% correct: 0.0\n",
      "--\n",
      "batch 1\n",
      "% wellformed: 99.487\n",
      "% api match: 47.423\n",
      "% correct: 38.462\n",
      "--\n",
      "batch 2\n",
      "% wellformed: 100.0\n",
      "% api match: 34.444\n",
      "% correct: 25.0\n",
      "--\n",
      "batch 3\n",
      "% wellformed: 96.923\n",
      "% api match: 96.296\n",
      "% correct: 71.795\n",
      "--\n",
      "total:\n",
      "% wellformed: 99.067\n",
      "% api match: 45.222\n",
      "% correct: 34.667\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "for round_ in range(1, 4):\n",
    "    print(\"round:\", round_)\n",
    "    print(\"=====\")\n",
    "    for i in range(round_+1):\n",
    "        print(\"batch\", i)\n",
    "        eval_batch(\"saved_results/CL_round_{}_no_replay.json\".format(round_), batches[i])\n",
    "        print(\"--\")\n",
    "    print(\"total:\")\n",
    "    eval_batch(\"saved_results/CL_round_{}_no_replay.json\".format(round_))\n",
    "    print(\"=============================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
